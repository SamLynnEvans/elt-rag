{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa7b76f-6901-475f-96d0-b9d5044f4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "if (ENV := os.getenv(\"ENV\")) is None:\n",
    "    raise RuntimeError(\"ENV must be set\")\n",
    "if (DUCKDB_PATH := os.getenv(\"DUCKDB_PATH\")) is None:\n",
    "    raise RuntimeError(\"DUCKDB_PATH must be set\")\n",
    "if (CHROMA_DB_DIR := os.getenv(\"CHROMA_DB_DIR\")) is None:\n",
    "    raise RuntimeError(\"CHROMA_DB_PATH must be set\")\n",
    "if (GEMINI_API_KEY := os.getenv(\"GEMINI_API_KEY\")) is None:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY must be set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58494731-e044-4ef7-9af3-96468a1e1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import date\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class RagRecord(BaseModel):\n",
    "    doc_id: int\n",
    "    document_title: str\n",
    "    last_modified: date\n",
    "    document_text: str\n",
    "    ticket_id: Optional[str]\n",
    "    priority: Optional[str]\n",
    "    department: Optional[str]\n",
    "    resolution_summary: Optional[str]\n",
    "    rag_chunk: str\n",
    "\n",
    "    def to_metadata(self) -> \"ChunkMetadata\":\n",
    "        return ChunkMetadata(\n",
    "            **self.model_dump(include=ChunkMetadata.model_fields.keys())\n",
    "        )\n",
    "\n",
    "\n",
    "class ChunkMetadata(BaseModel):\n",
    "    doc_id: int\n",
    "    document_title: str\n",
    "    last_modified: date\n",
    "    ticket_id: Optional[str]\n",
    "    priority: Optional[str]\n",
    "    department: Optional[str]\n",
    "    resolution_summary: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b9bb15-d00d-45c4-89a4-7cad1275947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "def stream_rag_records(db_path: str, batch_size: int=10) -> list[RagRecord]:\n",
    "    \"\"\"\n",
    "    Stream rows from the docs_for_rag table in DuckDB in fixed-size batches.\n",
    "\n",
    "    The query cursor fetches up to `batch_size` rows at a time using `fetchmany`,\n",
    "    which avoids loading the entire table into memory. Each batch is converted\n",
    "    into a list of RagRecord objects and yielded to the caller.\n",
    "\n",
    "    The `while True` loop terminates naturally when DuckDB returns an empty list,\n",
    "    signalling that all rows have been consumed.\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"SELECT * FROM {ENV}_marts.docs_for_rag\"\n",
    "    con = duckdb.connect(db_path, read_only=True)\n",
    "    result = con.execute(sql)\n",
    "    col_names = [c[0] for c in result.description]\n",
    "\n",
    "    while True:\n",
    "        rows = result.fetchmany(batch_size)\n",
    "        if not rows:\n",
    "            break\n",
    "\n",
    "        yield [RagRecord(**dict(zip(col_names, row))) for row in rows]\n",
    "\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def embed_texts(texts: list[str]) -> list[list[float]]:\n",
    "    \"\"\"Embed a batch of strings using Gemini embeddings.\"\"\"\n",
    "    \n",
    "    response = genai.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        content=texts\n",
    "    )\n",
    "    \n",
    "    return response['embedding']\n",
    "\n",
    "\n",
    "def chunk_text(text: str, max_words=500) -> list[str]:\n",
    "    \"\"\"\n",
    "    Simple word-based chunker. Splits text into chunks of up to `max_words`\n",
    "    while preserving word boundaries. Suitable for small datasets and demo RAG.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_words):\n",
    "        chunk_words = words[i : i + max_words]\n",
    "        chunks.append(\" \".join(chunk_words))\n",
    "\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c7e6db-e0f4-4972-80b4-7a0451bd6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "\n",
    "client = chromadb.PersistentClient(path=os.getenv(\"CHROMA_DB_DIR\"))\n",
    "\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"policy_rag\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"} \n",
    ")\n",
    "\n",
    "\n",
    "for records in stream_rag_records(DUCKDB_PATH):\n",
    "    all_chunks = []\n",
    "    all_ids = []\n",
    "    all_metadatas = []\n",
    "\n",
    "    for rec in records:\n",
    "        chunks = chunk_text(rec.rag_chunk)\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            meta = rec.to_metadata().model_dump(mode=\"json\")\n",
    "            meta[\"num_chunks\"] = len(chunks)\n",
    "            meta[\"chunk_index\"] = i\n",
    "            all_chunks.append(chunk)\n",
    "            all_ids.append(f\"{rec.doc_id}_{rec.ticket_id}_{i}\")\n",
    "            all_metadatas.append(meta)\n",
    "            \n",
    "    embeddings = embed_texts(all_chunks) \n",
    "    \n",
    "    collection.add(\n",
    "                ids=all_ids,\n",
    "                embeddings=embeddings,\n",
    "                documents=all_chunks,\n",
    "                metadatas=all_metadatas\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d978db-aa9c-4bb1-9cca-6c5b60195b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that number of records pulled from database equals number of entries in chroma.\n",
    "# We'd expect this not to match if there were larger chunks, but in the provided demo data it should be the same\n",
    "\n",
    "con = duckdb.connect(DUCKDB_PATH, read_only=True)\n",
    "assert len(con.query(f\"SELECT * FROM {ENV}_marts.docs_for_rag\").fetchall()) == collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de829f0-ded9-409a-81e5-0bf01020e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"display:flex; gap:40px;\">\n",
       "    <div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>department</th>\n",
       "      <th>duckdb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HR</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sales</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Finance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Legal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Security</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Procurement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Compliance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DevOps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>\n",
       "    <div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>department</th>\n",
       "      <th>chroma_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HR</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sales</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Finance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Engineering</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Legal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Compliance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DevOps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Procurement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Security</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test metadata parsing/upload: Roll up data in mart and collection to check they are the same\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def duckdb_rollup(db_path=\"/app/database/mydb.duckdb\"):\n",
    "    con = duckdb.connect(db_path, read_only=True)\n",
    "    df = con.execute(\n",
    "        f\"\"\"\n",
    "        SELECT department, COUNT(*) AS duckdb_count\n",
    "        FROM {ENV}_marts.docs_for_rag\n",
    "        GROUP BY department\n",
    "        ORDER BY duckdb_count DESC\n",
    "        \"\"\"\n",
    "    ).df()\n",
    "    con.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "def chroma_rollup(collection, batch_size=500):\n",
    "    dept_counter = Counter()\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        res = collection.get(\n",
    "            include=[\"metadatas\"],\n",
    "            limit=batch_size,\n",
    "            offset=offset\n",
    "        )\n",
    "\n",
    "        metadatas = res.get(\"metadatas\", [])\n",
    "        if not metadatas:\n",
    "            break\n",
    "\n",
    "        for m in metadatas:\n",
    "            dept = m.get(\"department\")\n",
    "            if dept is not None:\n",
    "                dept_counter[dept] += 1\n",
    "\n",
    "        offset += batch_size\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [{\"department\": d, \"chroma_count\": c} for d, c in dept_counter.items()]\n",
    "    ).sort_values(\"chroma_count\", ascending=False)\n",
    "    return df\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "duckdb_df = duckdb_rollup()\n",
    "chroma_df = chroma_rollup(collection)\n",
    "\n",
    "\n",
    "html = f\"\"\"\n",
    "<div style=\"display:flex; gap:40px;\">\n",
    "    <div>{duckdb_df.to_html(index=False)}</div>\n",
    "    <div>{chroma_df.to_html(index=False)}</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "942d2e22-b0ec-4ae7-bfff-71d20700ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search function to test semantic search\n",
    "\n",
    "def search(query: str, top_k: int = 1, where: dict | None = None) -> list[dict]:\n",
    "    embedding = embed_texts([query])[0]\n",
    "\n",
    "    \n",
    "    result = collection.query(\n",
    "        query_embeddings=[embedding],\n",
    "        n_results=top_k,\n",
    "        where=where\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"documents\": result[\"documents\"][0],\n",
    "        \"metadatas\": result[\"metadatas\"][0],\n",
    "        \"distances\": result[\"distances\"][0],\n",
    "        \"ids\": result[\"ids\"][0],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd984cf4-b0c2-46d1-be18-acd63b0a7628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IT',),\n",
       " ('Compliance',),\n",
       " ('Sales',),\n",
       " ('Finance',),\n",
       " ('HR',),\n",
       " ('Security',),\n",
       " ('Engineering',),\n",
       " ('Procurement',),\n",
       " ('DevOps',),\n",
       " ('Legal',),\n",
       " ('Marketing',)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate unique values for filtering\n",
    "\n",
    "con.query(f\"select distinct department from {ENV}_marts.docs_for_rag\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de55318-7249-4323-9837-8c676647b6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': ['Policy \"Employee Travel & Expense Guidelines\" (1002) states: Employees are limited to $150/night for hotel stays. Receipts must be uploaded within 14 days of travel completion. Failure to submit on time will result in a 30-day reimbursement delay. Airfare is strictly Economy class. Related ticket TKT-4522 (MEDIUM, Finance) was resolved as: User queried the $150 hotel limit. Confirmed policy applies to all domestic travel.',\n",
       "  'Policy \"Employee Travel & Expense Guidelines\" (1002) states: Employees are limited to $150/night for hotel stays. Receipts must be uploaded within 14 days of travel completion. Failure to submit on time will result in a 30-day reimbursement delay. Airfare is strictly Economy class. Related ticket TKT-4525 (HIGH, Sales) was resolved as: Disputed an Economy class booking for a long-haul flight. Policy confirmed no exceptions.'],\n",
       " 'metadatas': [{'department': 'Finance',\n",
       "   'last_modified': '2024-11-01',\n",
       "   'ticket_id': 'TKT-4522',\n",
       "   'document_title': 'Employee Travel & Expense Guidelines',\n",
       "   'priority': 'MEDIUM',\n",
       "   'chunk_index': 0,\n",
       "   'num_chunks': 1,\n",
       "   'resolution_summary': 'User queried the $150 hotel limit. Confirmed policy applies to all domestic travel.',\n",
       "   'doc_id': 1002},\n",
       "  {'priority': 'HIGH',\n",
       "   'chunk_index': 0,\n",
       "   'num_chunks': 1,\n",
       "   'resolution_summary': 'Disputed an Economy class booking for a long-haul flight. Policy confirmed no exceptions.',\n",
       "   'doc_id': 1002,\n",
       "   'ticket_id': 'TKT-4525',\n",
       "   'last_modified': '2024-11-01',\n",
       "   'department': 'Sales',\n",
       "   'document_title': 'Employee Travel & Expense Guidelines'}],\n",
       " 'distances': [0.36067700386047363, 0.368194580078125],\n",
       " 'ids': ['1002_TKT-4522_0', '1002_TKT-4525_0']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"hotel policy\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b297c95-babb-4fff-a026-b1633651d1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': ['Policy \"Paid Time Off (PTO) Accrual\" (1007) states: Full-time employees accrue 1.67 days of PTO per month. There is a maximum rollover of 5 days into the next calendar year. Sick time is managed separately and does not count against this balance. Related ticket TKT-4529 (LOW, HR) was resolved as: Employee asked about maximum PTO rollover. Confirmed 5-day limit.'],\n",
       " 'metadatas': [{'doc_id': 1007,\n",
       "   'last_modified': '2024-10-01',\n",
       "   'num_chunks': 1,\n",
       "   'department': 'HR',\n",
       "   'priority': 'LOW',\n",
       "   'document_title': 'Paid Time Off (PTO) Accrual',\n",
       "   'resolution_summary': 'Employee asked about maximum PTO rollover. Confirmed 5-day limit.',\n",
       "   'ticket_id': 'TKT-4529',\n",
       "   'chunk_index': 0}],\n",
       " 'distances': [0.2757105827331543],\n",
       " 'ids': ['1007_TKT-4529_0']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"how much monthly paid time off do employees get\", 1, {\"department\": \"HR\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
